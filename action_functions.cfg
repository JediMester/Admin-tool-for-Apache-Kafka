#!/bin/bash
#!/usr/bin/perl -w

### Action függvények

#declare -a sh_files=()

declare -a topics=()
declare -a operations=()

# Experimental shit - más formában van használva jelenleg: spawn_new_shell.sh
function new_login_shell() {
	xterm -hold ls

}

function stop_and_disable_kaf_for_loop() {
	
	for broker in ${kaf_broker_list[@]}; do
		get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
		echo "${LBL}Leállítás és service disable indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
		echo ""
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl stop kafka"
		countdown 30
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl disable kafka"
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl daemon-reload"
		echo "${LG}Service státusz:${NC} ${YEL}$get_broker_status${NC}"
		echo ""
	done

}

function start_and_enable_kaf_for_loop() {

	for broker in ${kaf_broker_list[@]}; do
		get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
		echo "${LBL}Indítás és service enable indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
		echo ""
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl enable kafka"
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl daemon-reload"
		sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl start kafka"
		countdown 30
		echo "${LG}Service státusz:${NC} ${YEL}$get_broker_status${NC}"
		echo ""
	done

}

# Rolling resi for loop PP-hoz (command különbségek miatt)
function rolling_res_pp_for_loop() {

	for broker in ${kaf_broker_list[@]}
			do
				broker_host=$(eval echo \${broker_list_${env}}$broker)
				controller_host=$(eval echo \${broker_list_${env}}$controller_node)
				
				#get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep -i active | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				get_broker_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				#if [[ "${broker}" != "${controller_node}" ]]; then
				if [[ "${broker_host}" != "${controller_host}" ]]; then
					#echo "${LBL}URP szám:${NC} ${YEL}${under_rep_partitions}${NC}"
					echo "${LBL}Restart indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
					echo ""
					sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
					echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
					echo ""
					countdown 15
					echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					echo ""
						if [[ ${get_broker_status} != "active(running)" ]]; then
							echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
							echo ""
							countdown 10
							echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						else
							echo "${LG}A restart sikeresen befejeződött.${NC}"
						fi
						
					if { [[ ${get_broker_status} != "active(running)" ]] && [[ ${under_rep_partitions} == 0 ]] ;}; then
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						echo ""
						echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
						echo ""
						sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
						echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
						countdown 15
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					else
						if [[ ${under_rep_partitions} != 0 ]]; then
							break
						fi
						
						under_rep_checker
						
						count=0
						while sleep 30; do
							under_rep_checker
							echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
							countdown 30
							if [[ ${under_rep_partitions} == 0 ]]; then
								break
							fi
						done
					fi
				
				else
					echo "${LBL}Kontroller node újraindul:${NC} ${YEL}${controller_host}${NC}"
					#get_controller_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
					controller_host=$(eval echo \${broker_list_${env}}$controller_node)
					get_controller_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}'")
					if [[ "${broker_host}" == "${controller_host}" ]]; then
						under_rep_checker
							if [[ ${under_rep_partitions} == 0 ]]; then
								sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
								echo "${LBL}Service státusz:${NC} ${LG}$get_controller_status${NC}"
								echo ""
									if [[ ${get_controller_status} != "active(running)" ]]; then
										echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
										#sleep 10
										echo ""
										countdown 10
									else
										echo "${LG}A restart sikeresen befejeződött. - ${NC}"$(date +%Y-%m-%d_%H-%M-%S)
									fi
							elif [[ ${under_rep_partitions} != 0 ]]; then
								
								break
															
								under_rep_checker
									
								count=0
								while sleep 30; do
									under_rep_checker
									echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
									countdown 30
									if [[ ${under_rep_partitions} == 0 ]]; then
										break
										echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
										echo ""
										sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
									fi
								done
							else
								echo "${LG}Nincs URP, a restart sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								
							fi
					fi
				fi
	done

}

# Rolling resi for loop UAT, DEV és PROD-hoz (command különbségek miatt)
function rolling_res_for_loop() {
	
	for broker in ${kaf_broker_list[@]}
			do
				broker_host=$(eval echo \${broker_list_${env}}$broker)
				controller_host=$(eval echo \${broker_list_${env}}$controller_node)
				
				get_broker_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				if [[ "${broker_host}" != "${controller_host}" ]]; then
					#echo "${LBL}URP szám:${NC} ${YEL}${under_rep_partitions}${NC}"
					echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
					echo ""
					sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
					echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
					echo ""
					countdown 15
					echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					echo ""
						if [[ ${get_broker_status} != "active(running)" ]]; then
							echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
							echo ""
							countdown 10
							echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						else
							echo "${LG}A restart sikeresen befejeződött.${NC}"
						fi
						
					if { [[ ${get_broker_status} != "active(running)" ]] && [[ ${under_rep_partitions} == 0 ]] ;}; then
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						echo ""
						echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
						echo ""
						sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
						echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
						countdown 15
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					else
						if [[ ${under_rep_partitions} != 0 ]]; then
							break
						fi
						
						under_rep_checker
						
						count=0
						while sleep 30; do
							under_rep_checker
							echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
							countdown 30
							if [[ ${under_rep_partitions} == 0 ]]; then
								break
								#echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								#echo ""
								#sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
							fi
						done
					fi
				 
				else
					echo "${LBL}Kontroller node újraindul:${NC} ${YEL}${controller_host}${NC}"
					#get_controller_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
					controller_host=$(eval echo \${broker_list_${env}}$controller_node)
					get_controller_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}'")
					if [[ "${broker_host}" == "${controller_host}" ]]; then
						under_rep_checker
							if [[ ${under_rep_partitions} == 0 ]]; then
								sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
								echo "${LBL}Service státusz:${NC} ${LG}$get_controller_status${NC}"
								echo ""
									if [[ ${get_controller_status} != "active(running)" ]]; then
										echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
										#sleep 10
										echo ""
										countdown 10
									else
										echo "${LG}A restart sikeresen befejeződött. - ${NC}"$(date +%Y-%m-%d_%H-%M-%S)
									fi
							elif [[ ${under_rep_partitions} != 0 ]]; then
								
								break
															
								under_rep_checker
									
								count=0
								while sleep 30; do
									under_rep_checker
									echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
									countdown 30
									if [[ ${under_rep_partitions} == 0 ]]; then
										break
										echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
										echo ""
										sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
									fi
								done
							else
								echo "${LG}Nincs URP, a restart sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								
							fi
					fi
							
				fi
	done

}

function make_pwd() {

	who_am_i="$(who am i | awk '{print $1}')"
	
	pw_dir="/home/kafka/pwd/"
	
	if [[ ! -d $pw_dir ]]; then
		mkdir -p $pw_dir
	fi
	
	pwd_file="$pw_dir$who_am_i.passwd"
	#secret_vault="$pw_dir.$who_am_i.secret"
	#remote_pwd=$(cat $secret_vault | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
	
	if [[ ! -f $pwd_file ]]; then
		touch $pwd_file
		#touch $secret_vault
		echo ""
		echo "${YEL}IPA jelszó:${NC} "
		read -s pwd && echo $pwd >> $pwd_file
		chmod +rwx $pwd_file
		remote_pwd=$(cat $pwd_file)
	else
		echo ""
		echo "${LG}IPA jelszó decrypt-álás folyamatban...${NC}"
		echo ""
		remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
	fi

}


# IPA jelszóhoz pwd fájl létrehozása, pw encrypt + decrypt mechanizmus, illetve kontroller bróker lekérés
function make_pwd_and_get_controller() {
	
	who_am_i="$(who am i | awk '{print $1}')"
	
	pw_dir="/home/kafka/pwd/"
	
	if [[ ! -d $pw_dir ]]; then
		mkdir -p $pw_dir
	fi
	
	pwd_file="$pw_dir$who_am_i.passwd"
	#secret_vault="$pw_dir.$who_am_i.secret"
	#remote_pwd=$(cat $secret_vault | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
	
	if [[ ! -f $pwd_file ]]; then
		touch $pwd_file
		#touch $secret_vault
		echo ""
		echo "${YEL}IPA jelszó:${NC} "
		read -s pwd && echo $pwd >> $pwd_file
		chmod +rwx $pwd_file
		#chmod +rwx $secret_vault
		#chown $who_am_i:$who_am_i $pwd_file
		#echo ""
		#echo "${YEL}IPA jelszó beolvasása pw encrypt-áláshoz.${NC}"
		#echo $pwd | openssl enc -base64 -e -salt -pbkdf2 -iter 100000 >> $pwd_file
		remote_pwd=$(cat $pwd_file)
	else
		echo ""
		echo "${LG}IPA jelszó decrypt-álás folyamatban...${NC}"
		echo ""
		remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
	fi
	
	dev_hosts=(srv01.dc02.dev.kafka.otpbank.hu srv02.dc02.dev.kafka.otpbank.hu srv03.dc02.dev.kafka.otpbank.hu srv04.dc02.dev.kafka.otpbank.hu srv05.dc02.dev.kafka.otpbank.hu srv06.dc02.dev.kafka.otpbank.hu)
	uat_hosts=(srv01.dc01.uat.kafka.otpbank.hu srv02.dc01.uat.kafka.otpbank.hu srv03.dc01.uat.kafka.otpbank.hu srv04.dc01.uat.kafka.otpbank.hu srv05.dc01.uat.kafka.otpbank.hu srv06.dc01.uat.kafka.otpbank.hu)
	pp_hosts=(srv01.dc01.preprod.kafka.otpbank.hu srv02.dc01.preprod.kafka.otpbank.hu srv03.dc01.preprod.kafka.otpbank.hu srv04.dc01.preprod.kafka.otpbank.hu srv01.dc02.preprod.kafka.otpbank.hu srv02.dc02.preprod.kafka.otpbank.hu srv03.dc02.preprod.kafka.otpbank.hu srv04.dc02.preprod.kafka.otpbank.hu)
	prod_hosts=(srv01.dc01.prod.kafka.otpbank.hu srv02.dc01.prod.kafka.otpbank.hu srv03.dc01.prod.kafka.otpbank.hu srv04.dc01.prod.kafka.otpbank.hu srv05.dc01.prod.kafka.otpbank.hu srv06.dc01.prod.kafka.otpbank.hu srv07.dc01.prod.kafka.otpbank.hu srv08.dc01.prod.kafka.otpbank.hu srv01.dc02.prod.kafka.otpbank.hu srv02.dc02.prod.kafka.otpbank.hu srv03.dc02.prod.kafka.otpbank.hu srv04.dc02.prod.kafka.otpbank.hu srv05.dc02.prod.kafka.otpbank.hu srv06.dc02.prod.kafka.otpbank.hu srv07.dc02.prod.kafka.otpbank.hu srv08.dc02.prod.kafka.otpbank.hu)

	get_env
	
	if [[ "${env}" == "ua" ]]; then
		kaf_broker_list="${uat_hosts[@]}"
	elif [[ "${env}" == "dv" ]]; then
		kaf_broker_list="${dev_hosts[@]}"
	elif [[ "${env}" == "pp" ]]; then
		kaf_broker_list="${pp_hosts[@]}"
	else
		kaf_broker_list="${prod_hosts[@]}"
	fi
	
	choose_zookeeper
	controller_broker=$($zookeeper_shell $selected_zookeeper get /brokers/ids/$(/opt/kafka/apache-kafka/bin/zookeeper-shell.sh $selected_zookeeper get /controller | tail -1 | jq .brokerid) | tail -1 | jq .endpoints[])
	if [[ "${env}" == "pp" ]]; then
		controller_node=$(echo $controller_broker | grep "SASL_SSL" | sed 's/.*\///' | awk -F '"' {'print $1'} | cut -c1-35)
	elif [[ "${env}" == "pr" ]]; then
		controller_node=$(echo $controller_broker | grep "SASL_SSL" | sed 's/.*\///' | awk -F '"' {'print $1'} | cut -c1-32)
	else
		controller_node=$(echo $controller_broker | grep "SASL_SSL" | sed 's/.*\///' | awk -F '"' {'print $1'} | cut -c1-31)
	fi
	
}

# Cluster rolling restart URP figyeléssel, URP esetén vár a függvény, míg az értéke 0 lesz, csak azután megy tovább a köv. brókerre
function rolling_restart() {
	
	make_pwd_and_get_controller
	
	if [[ ! -z $controller_node ]]; then
		controller_host=$(eval echo \${broker_list_${env}}$controller_node)
			
		kaf_broker_list=("${kaf_broker_list[@]/$controller_host}")
		
		kaf_broker_list+=("$controller_host")
	else
		kaf_broker_list="${kaf_broker_list[@]}"
	fi
	
	under_rep_partitions=0
	under_rep_checker
	running=true
	echo "${LBL}Rolling restart indul - ${NC}"$(date +%Y-%m-%d_%H-%M-%S)
	#get_controller_broker
	case ${env} in
	pp)
	while : ; do
		for broker in ${kaf_broker_list[@]}; do
			if [[ "$running" == "true" ]]; then
				broker_host=$(eval echo \${broker_list_${env}}$broker)
				controller_host=$(eval echo \${broker_list_${env}}$controller_node)
				
				#get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep -i active | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				get_broker_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				#if [[ "${broker}" != "${controller_node}" ]]; then
				if [[ "${broker_host}" != "${controller_host}" ]]; then
					#echo "${LBL}URP szám:${NC} ${YEL}${under_rep_partitions}${NC}"
					echo "${LBL}Restart indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
					echo ""
					sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
					echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
					echo ""
					countdown 15
					echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					echo ""
						if [[ ${get_broker_status} != "active(running)" ]]; then
							echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
							echo ""
							countdown 10
							echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						else
							echo "${LG}A restart sikeresen befejeződött.${NC}"
						fi
						
					if { [[ ${get_broker_status} != "active(running)" ]] && [[ ${under_rep_partitions} == 0 ]] ;}; then
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						echo ""
						echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
						echo ""
						sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
						echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
						countdown 15
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					else
						if [[ ${under_rep_partitions} != 0 ]]; then
							break
						fi
						
						under_rep_checker
						
						count=0
						while countdown 30; do
						#while sleep 30; do
							under_rep_checker
							echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
							#countdown 30
							if [[ ${under_rep_partitions} == 0 ]]; then
								break
							fi
						done
					fi
				
				else
					echo "${LBL}Kontroller node újraindul:${NC} ${YEL}${controller_host}${NC}"
					#get_controller_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
					controller_host=$(eval echo \${broker_list_${env}}$controller_node)
					get_controller_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}'")
					if [[ "${broker_host}" == "${controller_host}" ]]; then
						under_rep_checker
							if [[ ${under_rep_partitions} == 0 ]]; then
								sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
								echo "${LBL}Service státusz:${NC} ${LG}$get_controller_status${NC}"
								echo ""
									if [[ ${get_controller_status} != "active(running)" ]]; then
										echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
										#sleep 10
										echo ""
										countdown 10
									else
										echo "${LG}A restart sikeresen befejeződött. - ${NC}"$(date +%Y-%m-%d_%H-%M-%S)
									fi
							elif [[ ${under_rep_partitions} != 0 ]]; then
								
								break
															
								under_rep_checker
									
								count=0
								while countdown 30; do
								#while sleep 30; do
									under_rep_checker
									echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
									#countdown 30
									if [[ ${under_rep_partitions} == 0 ]]; then
										break
										echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
										echo ""
										sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} -t "sudo su - kafka; sudo systemctl restart kafka"
									fi
								done
							else
								echo "${LG}Nincs URP, a restart sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								
							fi
					fi
				fi
			
			fi
			
				
			# Az 's' billentyű lenyomásával stop-olható a for loop, illetve újra elindítható (ha pl. a jelszó átadás az sshpass-nak bug miatt nem sikerül)
			if read -sn 1 -t 0.25 key && [[ "$key" = "s" ]] ; then
				if [[ "$running" == "true" ]]; then
					running=false
					
					rm -rfv $pwd_file
					
					who_am_i="$(who am i | awk '{print $1}')"
		
					pw_dir="/home/kafka/pwd/"
		
					if [[ ! -d $pw_dir ]]; then
						mkdir -p $pw_dir
					fi
		
					pwd_file="$pw_dir$who_am_i.passwd"
		
					if [[ ! -f $pwd_file ]]; then
						touch $pwd_file
						echo "${YEL}IPA jelszó:${NC} "
						read -s pwd && echo $pwd >> $pwd_file
						chmod +rwx $pwd_file
						remote_pwd=$(cat $pwd_file)
					else
						echo "${YEL}IPA jelszó decrypt-álás folyamatban...${NC}"
						echo ""
						remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
					fi
				
					rolling_res_pp_for_loop
			
				else
					running=true
				fi
			fi
		done
		
		break
		#continue
	
	done
	;;
				
	*)
	while : ; do
		for broker in ${kaf_broker_list[@]}; do
			if [[ "$running" == "true" ]]; then
				broker_host=$(eval echo \${broker_list_${env}}$broker)
				controller_host=$(eval echo \${broker_list_${env}}$controller_node)
				
				get_broker_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
				if [[ "${broker_host}" != "${controller_host}" ]]; then
					#echo "${LBL}URP szám:${NC} ${YEL}${under_rep_partitions}${NC}"
					echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
					echo ""
					sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
					echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
					echo ""
					countdown 15
					echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					echo ""
						if [[ ${get_broker_status} != "active(running)" ]]; then
							echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
							echo ""
							countdown 10
							echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						else
							echo "${LG}A restart sikeresen befejeződött.${NC}"
						fi
						
					if { [[ ${get_broker_status} != "active(running)" ]] && [[ ${under_rep_partitions} == 0 ]] ;}; then
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
						echo ""
						echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
						echo ""
						sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
						echo "Várunk ${YEL}15 sec-et${NC}, hogy a restart befejeződjön..."
						countdown 15
						echo "${LBL}Service státusz:${NC} ${LG}$get_broker_status${NC}"
					else
						if [[ ${under_rep_partitions} != 0 ]]; then
							break
						fi
						
						under_rep_checker
						
						count=0
						while countdown 30; do
						#while sleep 30; do
							under_rep_checker
							echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
							#countdown 30
							if [[ ${under_rep_partitions} == 0 ]]; then
								break
								#echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								#echo ""
								#sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
							fi
						done
					fi
				 
				else
					echo "${LBL}Kontroller node újraindul:${NC} ${YEL}${controller_host}${NC}"
					#get_controller_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
					controller_host=$(eval echo \${broker_list_${env}}$controller_node)
					get_controller_status=$(sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${controller_host} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}'")
					if [[ "${broker_host}" == "${controller_host}" ]]; then
						under_rep_checker
							if [[ ${under_rep_partitions} == 0 ]]; then
								sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
								echo "${LBL}Service státusz:${NC} ${LG}$get_controller_status${NC}"
								echo ""
									if [[ ${get_controller_status} != "active(running)" ]]; then
										echo "Várunk még ${YEL}10 sec-et${NC}, hogy a restart biztosan befejeződjön..."
										#sleep 10
										echo ""
										countdown 10
									else
										echo "${LG}A restart sikeresen befejeződött. - ${NC}"$(date +%Y-%m-%d_%H-%M-%S)
									fi
							elif [[ ${under_rep_partitions} != 0 ]]; then
								
								break
															
								under_rep_checker
									
								count=0
								while countdown 30; do
								#while sleep 30; do
									under_rep_checker
									echo "Várunk ${YEL}30 sec-et${NC} a következő URP check-ig..."
									#countdown 30
									if [[ ${under_rep_partitions} == 0 ]]; then
										break
										echo "${LBL}Restart indul:${NC} ${YEL}$broker_host${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
										echo ""
										sshpass -p $remote_pwd ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker_host} "~/bin/asroot systemctl restart kafka"
									fi
								done
							else
								echo "${LG}Nincs URP, a restart sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
								
							fi
					fi
							
				fi
			
			fi	
			
			# Az 's' billentyű lenyomásával stop-olható a for loop, illetve újra elindítható (ha pl. a jelszó átadás az sshpass-nak bug miatt nem sikerül)
			if read -sn 1 -t 0.25 key && [[ "$key" = "s" ]] ; then
				if [[ "$running" == "true" ]]; then
					running=false
					
					rm -rfv $pwd_file
					
					who_am_i="$(who am i | awk '{print $1}')"
		
					pw_dir="/home/kafka/pwd/"
		
					if [[ ! -d $pw_dir ]]; then
						mkdir -p $pw_dir
					fi
		
					pwd_file="$pw_dir$who_am_i.passwd"
		
					if [[ ! -f $pwd_file ]]; then
						touch $pwd_file
						echo "${YEL}IPA jelszó:${NC} "
						read -s pwd && echo $pwd >> $pwd_file
						chmod +rwx $pwd_file
						remote_pwd=$(cat $pwd_file)
					else
						echo "${YEL}IPA jelszó decrypt-álás folyamatban...${NC}"
						echo ""
						remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
					fi
					
					rolling_res_for_loop
				
				else
					running=true
				fi
			fi
		done
		
		break
	
	done	
	;;
	esac
					
		#done
		#
		#break
		##continue
	
	#done
	
	sleep 1.5
	echo "${GRE}A rolling restart sikeresen befejeződött!${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
	
	#rm -rfv ${pwd_file}
	#echo "${RED}Jelszó fájl törölve!${NC}"
	echo ""
	echo "${LG}IPA jelszó encrypt-álás folyamatban...${NC}"
	echo $pwd | openssl enc -base64 -e -salt -pbkdf2 -iter 100000 >> $pwd_file
	echo ""
	echo "${LG}Jelszó levédve.${NC}"
	echo ""
	

}

function stop_and_disable_kaf() {
	
	make_pwd
	
	dev_hosts=(srv01.dc02.dev.kafka.otpbank.hu srv02.dc02.dev.kafka.otpbank.hu srv03.dc02.dev.kafka.otpbank.hu srv04.dc02.dev.kafka.otpbank.hu srv05.dc02.dev.kafka.otpbank.hu srv06.dc02.dev.kafka.otpbank.hu)
	uat_hosts=(srv01.dc01.uat.kafka.otpbank.hu srv02.dc01.uat.kafka.otpbank.hu srv03.dc01.uat.kafka.otpbank.hu srv04.dc01.uat.kafka.otpbank.hu srv05.dc01.uat.kafka.otpbank.hu srv06.dc01.uat.kafka.otpbank.hu)
	#pp_hosts=(srv01.dc01.preprod.kafka.otpbank.hu srv02.dc01.preprod.kafka.otpbank.hu srv03.dc01.preprod.kafka.otpbank.hu srv04.dc01.preprod.kafka.otpbank.hu srv01.dc02.preprod.kafka.otpbank.hu srv02.dc02.preprod.kafka.otpbank.hu srv03.dc02.preprod.kafka.otpbank.hu srv04.dc02.preprod.kafka.otpbank.hu)
	pp_dc01=(srv01.dc01.preprod.kafka.otpbank.hu srv02.dc01.preprod.kafka.otpbank.hu srv03.dc01.preprod.kafka.otpbank.hu srv04.dc01.preprod.kafka.otpbank.hu)
	pp_dc02=(srv01.dc02.preprod.kafka.otpbank.hu srv02.dc02.preprod.kafka.otpbank.hu srv03.dc02.preprod.kafka.otpbank.hu srv04.dc02.preprod.kafka.otpbank.hu)
	#prod_hosts=(srv01.dc01.prod.kafka.otpbank.hu srv02.dc01.prod.kafka.otpbank.hu srv03.dc01.prod.kafka.otpbank.hu srv04.dc01.prod.kafka.otpbank.hu srv05.dc01.prod.kafka.otpbank.hu srv06.dc01.prod.kafka.otpbank.hu srv07.dc01.prod.kafka.otpbank.hu srv08.dc01.prod.kafka.otpbank.hu srv01.dc02.prod.kafka.otpbank.hu srv02.dc02.prod.kafka.otpbank.hu srv03.dc02.prod.kafka.otpbank.hu srv04.dc02.prod.kafka.otpbank.hu srv05.dc02.prod.kafka.otpbank.hu srv06.dc02.prod.kafka.otpbank.hu srv07.dc02.prod.kafka.otpbank.hu srv08.dc02.prod.kafka.otpbank.hu)
	prod_dc01=(srv01.dc01.prod.kafka.otpbank.hu srv02.dc01.prod.kafka.otpbank.hu srv03.dc01.prod.kafka.otpbank.hu srv04.dc01.prod.kafka.otpbank.hu srv05.dc01.prod.kafka.otpbank.hu srv06.dc01.prod.kafka.otpbank.hu srv07.dc01.prod.kafka.otpbank.hu srv08.dc01.prod.kafka.otpbank.hu)
	prod_dc02=(srv01.dc02.prod.kafka.otpbank.hu srv02.dc02.prod.kafka.otpbank.hu srv03.dc02.prod.kafka.otpbank.hu srv04.dc02.prod.kafka.otpbank.hu srv05.dc02.prod.kafka.otpbank.hu srv06.dc02.prod.kafka.otpbank.hu srv07.dc02.prod.kafka.otpbank.hu srv08.dc02.prod.kafka.otpbank.hu)
	
	#get_env
	
	if [[ "$env" == "ua" ]]; then
		kaf_broker_list="${uat_hosts[@]}"
	elif [[ "$env" == "dv" ]]; then
		kaf_broker_list="${dev_hosts[@]}"
	elif [[ "$env" == "pp" ]]; then
		case ${dc_option} in
		1)
			kaf_broker_list="${pp_dc01[@]}"
			;;
		2)
			kaf_broker_list="${pp_dc02[@]}"
			;;
		esac
	else
		case ${dc_option} in
		1)
			kaf_broker_list="${prod_dc01[@]}"
			;;
		2)
			kaf_broker_list="${prod_dc02[@]}"
			;;
		esac
	fi
	
	for broker in ${kaf_broker_list[@]}; do
		if [[ "$running" == "true" ]]; then
			get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
			echo "${LBL}Leállítás és service disable indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
			echo ""
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl stop kafka"
			countdown 30
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl disable kafka"
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl daemon-reload"
			echo "${LG}Service státusz:${NC} ${YEL}$get_broker_status${NC}"
			echo ""
		fi
		
		if read -sn 1 -t 0.25 key && [[ "$key" = "s" ]] ; then
			if [[ "$running" == "true" ]]; then
				running=false
				
				rm -rfv $pwd_file
				
				who_am_i="$(who am i | awk '{print $1}')"
		
				pw_dir="/home/kafka/pwd/"
		
				if [[ ! -d $pw_dir ]]; then
					mkdir -p $pw_dir
				fi
		
				pwd_file="$pw_dir$who_am_i.passwd"
		
				if [[ ! -f $pwd_file ]]; then
					touch $pwd_file
					echo "${YEL}IPA jelszó:${NC} "
					read -s pwd && echo $pwd >> $pwd_file
					chmod +rwx $pwd_file
					remote_pwd=$(cat $pwd_file)
				else
					echo "${YEL}IPA jelszó decrypt-álás folyamatban...${NC}"
					echo ""
					remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
				fi
				
				stop_and_disable_kaf_for_loop
				
			else
				running=true
			fi
		fi
	done
	
	echo "${LG}Service leállítás sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
	
	#rm -rf ${pwd_file}
	#echo "${RED}Jelszó fájl törölve!${NC}"
	echo ""
	echo "${LG}IPA jelszó encrypt-álás folyamatban...${NC}"
	echo $pwd | openssl enc -base64 -e -salt -pbkdf2 -iter 100000 >> $pwd_file
	echo ""
	echo "${LG}Jelszó levédve.${NC}"
	echo ""
	
}

function start_and_enable_kaf() {
	
	make_pwd
	
	dev_hosts=(srv01.dc02.dev.kafka.otpbank.hu srv02.dc02.dev.kafka.otpbank.hu srv03.dc02.dev.kafka.otpbank.hu srv04.dc02.dev.kafka.otpbank.hu srv05.dc02.dev.kafka.otpbank.hu srv06.dc02.dev.kafka.otpbank.hu)
	uat_hosts=(srv01.dc01.uat.kafka.otpbank.hu srv02.dc01.uat.kafka.otpbank.hu srv03.dc01.uat.kafka.otpbank.hu srv04.dc01.uat.kafka.otpbank.hu srv05.dc01.uat.kafka.otpbank.hu srv06.dc01.uat.kafka.otpbank.hu)
	#pp_hosts=(srv01.dc01.preprod.kafka.otpbank.hu srv02.dc01.preprod.kafka.otpbank.hu srv03.dc01.preprod.kafka.otpbank.hu srv04.dc01.preprod.kafka.otpbank.hu srv01.dc02.preprod.kafka.otpbank.hu srv02.dc02.preprod.kafka.otpbank.hu srv03.dc02.preprod.kafka.otpbank.hu srv04.dc02.preprod.kafka.otpbank.hu)
	pp_dc01=(srv01.dc01.preprod.kafka.otpbank.hu srv02.dc01.preprod.kafka.otpbank.hu srv03.dc01.preprod.kafka.otpbank.hu srv04.dc01.preprod.kafka.otpbank.hu)
	pp_dc02=(srv01.dc02.preprod.kafka.otpbank.hu srv02.dc02.preprod.kafka.otpbank.hu srv03.dc02.preprod.kafka.otpbank.hu srv04.dc02.preprod.kafka.otpbank.hu)
	#prod_hosts=(srv01.dc01.prod.kafka.otpbank.hu srv02.dc01.prod.kafka.otpbank.hu srv03.dc01.prod.kafka.otpbank.hu srv04.dc01.prod.kafka.otpbank.hu srv05.dc01.prod.kafka.otpbank.hu srv06.dc01.prod.kafka.otpbank.hu srv07.dc01.prod.kafka.otpbank.hu srv08.dc01.prod.kafka.otpbank.hu srv01.dc02.prod.kafka.otpbank.hu srv02.dc02.prod.kafka.otpbank.hu srv03.dc02.prod.kafka.otpbank.hu srv04.dc02.prod.kafka.otpbank.hu srv05.dc02.prod.kafka.otpbank.hu srv06.dc02.prod.kafka.otpbank.hu srv07.dc02.prod.kafka.otpbank.hu srv08.dc02.prod.kafka.otpbank.hu)
	prod_dc01=(srv01.dc01.prod.kafka.otpbank.hu srv02.dc01.prod.kafka.otpbank.hu srv03.dc01.prod.kafka.otpbank.hu srv04.dc01.prod.kafka.otpbank.hu srv05.dc01.prod.kafka.otpbank.hu srv06.dc01.prod.kafka.otpbank.hu srv07.dc01.prod.kafka.otpbank.hu srv08.dc01.prod.kafka.otpbank.hu)
	prod_dc02=(srv01.dc02.prod.kafka.otpbank.hu srv02.dc02.prod.kafka.otpbank.hu srv03.dc02.prod.kafka.otpbank.hu srv04.dc02.prod.kafka.otpbank.hu srv05.dc02.prod.kafka.otpbank.hu srv06.dc02.prod.kafka.otpbank.hu srv07.dc02.prod.kafka.otpbank.hu srv08.dc02.prod.kafka.otpbank.hu)
	
	#get_env
	
	if [[ "$env" == "ua" ]]; then
		kaf_broker_list="${uat_hosts[@]}"
	elif [[ "$env" == "dv" ]]; then
		kaf_broker_list="${dev_hosts[@]}"
	elif [[ "$env" == "pp" ]]; then
		case ${dc_option} in
		1)
			kaf_broker_list="${pp_dc01[@]}"
			;;
		2)
			kaf_broker_list="${pp_dc02[@]}"
			;;
		esac
	else
		case ${dc_option} in
		1)
			kaf_broker_list="${prod_dc01[@]}"
			;;
		2)
			kaf_broker_list="${prod_dc02[@]}"
			;;
		esac
	fi
	
	for broker in ${kaf_broker_list[@]}; do
		if [[ "$running" == "true" ]]; then
			get_broker_status=$(sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "systemctl status kafka | grep 'Active:' | awk '{print \$2 \$3}' | tr -d '\n\t\r '")
			echo "${LBL}Indítás és service enable indul:${NC} ${YEL}$broker${NC} - "$(date +%Y-%m-%d_%H-%M-%S)
			echo ""
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl enable kafka"
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl daemon-reload"
			sshpass -f $pwd_file ssh -o stricthostkeychecking=no -A ${who_am_i}@${broker} "~/bin/asroot systemctl start kafka"
			countdown 30
			echo "${LG}Service státusz:${NC} ${YEL}$get_broker_status${NC}"
			echo ""
		fi
		
		if read -sn 1 -t 0.25 key && [[ "$key" = "s" ]] ; then
			if [[ "$running" == "true" ]]; then
				running=false
				
				rm -rfv $pwd_file
				
				who_am_i="$(who am i | awk '{print $1}')"
		
				pw_dir="/home/kafka/pwd/"
		
				if [[ ! -d $pw_dir ]]; then
					mkdir -p $pw_dir
				fi
		
				pwd_file="$pw_dir$who_am_i.passwd"
		
				if [[ ! -f $pwd_file ]]; then
					touch $pwd_file
					echo "${YEL}IPA jelszó:${NC} "
					read -s pwd && echo $pwd >> $pwd_file
					chmod +rwx $pwd_file
					remote_pwd=$(cat $pwd_file)
				else
					echo "${YEL}IPA jelszó decrypt-álás folyamatban...${NC}"
					echo ""
					remote_pwd=$(cat $pwd_file | openssl enc -base64 -d -salt -pbkdf2 -iter 100000)
				fi
				
				start_and_enable_kaf_for_loop
			
			else
				running=true
			fi
		fi
		
	done
	
	echo "${LG}Service indítás sikeresen befejeződött!{NC} - "$(date +%Y-%m-%d_%H-%M-%S)
	
	#rm -rf ${pwd_file}
	#echo "${RED}Jelszó fájl törölve!${NC}"
	echo ""
	echo "${LG}IPA jelszó encrypt-álás folyamatban...${NC}"
	echo $pwd | openssl enc -base64 -e -salt -pbkdf2 -iter 100000 >> $pwd_file
	echo ""
	echo "${LG}Jelszó levédve.${NC}"
	echo ""

}

function delete_rights() {
	
	topics+="$topic"
	operations+="$operation"
	#for operation in "${operations[@]}";
	for index in "${!topics[@]}";
		do
			topic=${topics[$index]}
			operation=${operations[$index]}
			
			"$kafka_acls_path" --remove --allow-principal User:"$user" --operation "$operation" --topic "$topic" --authorizer-properties zookeeper.connect="$selected_zookeeper"
			#echo "$del_right_cmd" >> "$sh_file"
		done
		
	#cat "$sh_file"
}


function delete_topic() {
	
	topics+="$topic"
	for topic in "${topics[@]}";
		do
			"$kafka_topics_path" --bootstrap-server "$selected_broker" --delete --topic "$topic"
			#echo "$del_topic_cmd" >> "$sh_file"
		done
	
	#cat "$sh_file"

}

function describe_topic() {
	
	topics+="$topic"
	for topic in "${topics[@]}";
		do
			#desc_topic_cmd="$kafka_consumer_gr_path --bootstrap-server $selected_broker --command-config $consumer_properties --describe --topic $topic --all-groups"
			desc_topic_cmd="$kafka_topics_path --bootstrap-server=$selected_broker --describe --topic $topic --command-config $consumer_properties"
			echo "$desc_topic_cmd" >> "$sh_file"
		done
	
	cat "$sh_file"
}

function get_user_acl() {
	
	user_acl_cmd="$kafka_acls_path --bootstrap-server=$selected_broker --command-config $command_config_properties --list --principal User:$user"
	topic_acl_cmd="$kafka_acls_path --bootstrap-server=$selected_broker --command-config $command_config_properties --list --topic $topic"
	
	if [[ $user_or_topic == "1" ]]; then
		echo "$user_acl_cmd" >> "$sh_file"
		cat "$sh_file"
		
	else
		echo "$topic_acl_cmd" >> "$sh_file"
		cat "$sh_file"
		
	fi

}

function get_acl_complex() {
	user_acl_cmd="$kafka_acls_path --bootstrap-server=$selected_broker --command-config=$command_config_properties --list --principal User:$user"
	topic_acl_cmd="$kafka_acls_path --bootstrap-server=$selected_broker --command-config=$command_config_properties --list --topic $topic"
	
	if [[ $user_or_topic == "1" ]]; then
		#echo "$user_acl_cmd" >> "$acl_file"
		$user_acl_cmd
	else
		#echo "$topic_acl_cmd" >> "$acl_file"
		$topic_acl_cmd
	fi
}

function consume_message() {
	
	consume_command="$kafka_console_consumer --bootstrap-server $selected_broker --topic $topic --from-beginning >> /home/kafka/$message_txt"
	echo "$consume_command" >> "$sh_file"
	cat "$sh_file"

}

function produce_message() {
	
	produce_command="$kafka_console_producer --bootstrap-server $selected_broker --producer.config=$producer_properties --topic $topic < /home/kafka/$message_txt"
	echo "$produce_command" >> "$sh_file"
	cat "$sh_file"
}

function last_offset_per_partition() {

	last_offset_command="$kafka_run_class kafka.tools.GetOffsetShell --broker-list $selected_broker --command-config $command_config_properties --topic $topic | awk -F  ":" '{sum += $3} END {print \"Result: \"sum}'"
	echo "$last_offset_command" >> "$sh_file"
	cat "$sh_file"
}

function create_topic() {
	
	#sh_files+=(""$sh_file"")
	
	local zk_port=2181
	
	if [[ "$kafka_version" == "2.7.0" ]]; then
		echo "$kafka_topics_path --create --topic $topic --zookeeper $selected_zookeeper:$zk_port --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
		#echo "$kafka_topics_path --create --topic $topic --zookeeper $selected_zookeeper --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
		
	else
		echo "$kafka_topics_path --create --bootstrap-server $selected_broker --command-config $consumer_properties  --topic $topic --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
		
	fi
	
}	

function create_topic_simple_ot() {	
	
	#sh_files+=(""$sh_file"")
	
	if [[ ${LOGGING} == "true" ]]; then
		echo "$kafka_topics_path --create --topic $topic --zookeeper $selected_zookeeper:$zk_port --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
		
	else
		echo "$kafka_topics_path --create --topic $topic --zookeeper $selected_zookeeper:$zk_port --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
	
	fi
}

#function create_topic() {
#	if { ( [[ "$there_is_csv" == "yes" ]] && [[ ${csv_file_type} == "complex" ]] && [[ "$action" == "1" ]] ) || \
#		 ( [[ "$there_is_csv" == "yes" ]] && [[ ${csv_file_type} == "simple_only_topics" ]] && [[ "$action" == "4" ]] ) || \
#		 ( [[ "$there_is_csv" == "no" ]] && [[ "$action" == "1" ]] ) && \
#		 [[ ! -z "$topic" ]] && [[ ! -z "$replication_factor" ]] && [[ ! -z "$partitions" ]] ;}
#	then
#		if [[ "${LOGGING}" == "true" ]]; then
#			#if [[ "$kafka_version" == "2.7.0" ]]; then
#				"$kafka_topics_path" --create --topic "$topic" --zookeeper "$selected_zookeeper":"$zk_port" --partitions "$partitions" --replication-factor "$replication_factor"
#				
#				log_mgmt "$ticket_num"
#				
#				log_zipper
#			#else
#			#	#"$kafka_topics_path" --create --bootstrap-server "$selected_broker":"$bts_port" --command-config "$consumer_properties" --partitions "$partitions" --replication-factor "$replication_factor" --topic "$topic"
#			#	"$kafka_topics_path" --create --bootstrap-server "$selected_broker" --command-config "$consumer_properties"  --topic "$topic" --partitions "$partitions" --replication-factor "$replication_factor"
#			#	
#			#	log_mgmt "$ticket_num"
#			#	
#			#	log_zipper
#			#fi
#		else
#			#if [[ "$kafka_version" == "2.7.0" ]]; then
#				"$kafka_topics_path" --create --topic "$topic" --zookeeper "$selected_zookeeper":"$zk_port" --partitions "$partitions" --replication-factor "$replication_factor"
#				
#			#else
#			#	#"$kafka_topics_path" --create --bootstrap-server "$selected_broker":"$bts_port" --command-config "$consumer_properties" --partitions "$partitions" --replication-factor "$replication_factor" --topic "$topic"
#			#	"$kafka_topics_path" --create --bootstrap-server "$selected_broker" --command-config "$consumer_properties"  --topic "$topic" --partitions "$partitions" --replication-factor "$replication_factor"
#			#fi
#			
#		fi
#		
#	else
#		local missing_vars=()
#		[ -z "$topic" ] && missing_vars=+"$topic"
#		[ -z "$replication_factor" ] && missing_vars=+"$replication_factor"
#		[ -z "$partitions" ] && missing_vars=+"$partitions"
#		
#		check_error "$kafka_topics_path --create" "${missing_vars[@]}"
#	fi	
#}

function create_topic_with_retention() {
	
	#sh_files+=(""$sh_file"")
	
	local zk_port=2181

	if [[ "$kafka_version" == "2.7.0" ]]; then
		echo "$kafka_topics_path --create --zookeeper $selected_zookeeper:$zk_port --create --topic $topic --config retention.ms=$day_to_ms_retention --partitions $partitions --replication-factor $replication_factor" #>> "$sh_file"
		
	else
		echo "$kafka_topics_path --create --bootstrap-server $selected_broker --command-config $consumer_properties  --topic $topic --partitions $partitions --replication-factor $replication_factor  --config retention.ms=$day_to_ms_retention" #>> "$sh_file"
		
	fi
}

function create_consumer_complex_csv() {
	
	#sh_files+=(""$sh_file"")
	
	case $action in
	
	3)
		if [[ "$kafka_version" == "2.7.0" ]]; then
			echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic_read --group $group_id"	
			
		else
			echo "$kafka_acls_path --bootstrap-server $selected_broker --add --consumer --allow-principal User:$user --topic $topic_read --group $group_id --command-config $consumer_properties"
			
		fi
		;;
	
	4)
		if [[ ! -z "$is_prefixed" ]]; then
			if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic_read --group $group_id-"
				
			else
				case $answer in
				
				2)
					echo "$kafka_acls_path --bootstrap-server $selected_broker --add --consumer --allow-principal User:$user --topic $topic_read --group $group_id- --command-config $consumer_properties"
					;;
				1)
					echo "$kafka_acls_path --bootstrap-server $selected_broker --add --consumer --allow-principal User:$user --topic $topic_read --group $group_id_prefix- --command-config $consumer_properties"
					;;
				esac
				
			fi
		
		fi
		;;
	esac
}

function create_consumer() {
	# Experimental shit (error kiíratás)
	#local actual_cmd=""
	
	#sh_files+=(""$sh_file"")
	
	if { [[ "$there_is_csv" == "no" ]] && [[ "$action" == "3" ]] ;}; then
		if [[ "$is_prefixed" == "no" ]]; then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic --group $consumer_group" #>> "$sh_file"
				
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --command-config "$consumer_properties" --add --consumer --allow-principal User:"$user" --topic "$topic" --group "$consumer_group" --command-config "$consumer_properties"
			#
			#fi	
		elif [[ "$is_prefixed" == "yes" ]]; then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic --group $consumer_group-" #>> "$sh_file"
			
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --consumer --allow-principal User:"$user" --topic "$topic" --group "$consumer_group-" --command-config "$consumer_properties"
			#
			#fi
		fi
		
	elif { [[ "$there_is_csv" == "yes" ]] && [[ "${csv_file_type}" == "simple_only_topics" ]] && [[ "$action" == "6" ]] ;}; then
		if [[ "$is_prefixed" == "no" ]]; then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic --group $consumer_group" #>> "$sh_file"
				
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --consumer --allow-principal User:"$user" --topic "$topic" --group "$consumer_group" --command-config "$consumer_properties"
			#
			#fi
		elif [[ "$is_prefixed" == "yes" ]]; then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --consumer --allow-principal User:$user --topic $topic --group $consumer_group-" #>> "$sh_file"
				
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --consumer --allow-principal User:"$user" --topic "$topic" --group "$consumer_group-" --command-config "$consumer_properties"
			#
			#fi
		fi
			
	else
		local missing_vars=()
		[ -z "$user" ] && missing_vars=+"$user"
		[ -z "$topic" ] && missing_vars=+"$topic"
		[ -z "$consumer_group" ] && missing_vars=+"$consumer_group"
		
		check_error "$kafka_acls_path --add consumer" "${missing_vars[@]}"
		
	fi
	
	
	
}

function create_producer_complex_csv() {
	
	#sh_files+=("$sh_file")
	
	case $action in
	
	#if [[ "$action" == "5" ]]; then
	5)
		if [[ "$kafka_version" == "2.7.0" ]]; then
			echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --producer --allow-principal User:$user --topic $topic_write"
			
		else
			echo "$kafka_acls_path --bootstrap-server $selected_broker --add --producer --allow-principal User:$user --topic $topic_write --command-config $producer_properties"
			
		fi
		;;
	6)
		if [[ "$kafka_version" == "2.7.0" ]]; then
			echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --producer --allow-principal User:$user --topic $topic_write --resource-pattern-type PREFIXED"
			
		else
			echo "$kafka_acls_path --bootstrap-server $selected_broker --add --producer --allow-principal User:$user --topic $topic_write --resource-pattern-type PREFIXED --command-config $producer_properties"
			
		fi
		;;
	esac
}

function create_producer() {
	
	#sh_files+=("$sh_file")
	
	if [[ "$there_is_csv" == "no" ]]; then
		if [[ "$action" == "4" ]]; then
			if [[ "$kafka_version" == "2.7.0" ]]; then
				"$kafka_acls_path" --authorizer-properties zookeeper.connect="$selected_zookeeper" --add --producer --allow-principal User:"$user" --topic "$topic"
			
			else
				"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --producer --allow-principal User:"$user" --topic "$topic" --command-config "$producer_properties"	
			
			fi
			
		elif [[ "$action" == "5" ]]; then
			if [[ "$kafka_version" == "2.7.0" ]]; then
				"$kafka_acls_path" --authorizer-properties zookeeper.connect="$selected_zookeeper" --add --producer --allow-principal User:"$user" --topic "$topic" --resource-pattern-type PREFIXED
				
			else
				"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --producer --allow-principal User:"$user" --topic "$topic" --resource-pattern-type PREFIXED --command-config "$producer_properties"
				
			fi
		else
			if [[ "$kafka_version" == "2.7.0" ]]; then
				"$kafka_acls_path" --authorizer-properties zookeeper.connect="$selected_zookeeper" --add --producer --allow-principal User:"$user" --topic "$topic" --resource-pattern-type PREFIXED
			else
				"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --producer --allow-principal User:"$user" --topic "$topic" --resource-pattern-type PREFIXED --command-config "$producer_properties"
			fi
		fi
	
	elif [[ "$there_is_csv" == "yes" ]]; then
		if { ( [[ ${csv_file_type} == "simple" ]] && [[ "$action" == "3" ]] ) || \
			 ( [[ ${csv_file_type} == "simple_only_topics" ]] && [[ "$action" == "2" ]] ) ;}
		then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --producer --allow-principal User:$user --topic $topic" #>> "$sh_file"
				
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --producer --allow-principal User:"$user" --topic "$topic" --command-config "$producer_properties"
			#	
			#	log_mgmt "$ticket_num"
			#	
			#	log_zipper
			#fi
			
		elif { ( [[ ${csv_file_type} == "simple" ]] && [[ "$action" == "2" ]] ) || \
			   ( [[ ${csv_file_type} == "simple_only_topics" ]] && [[ "$action" == "3" ]] ) ;}
		then
			#if [[ "$kafka_version" == "2.7.0" ]]; then
				echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --producer --allow-principal User:$user --topic $topic --resource-pattern-type PREFIXED" #>> "$sh_file"
				
			#else
			#	"$kafka_acls_path" --bootstrap-server "$selected_broker" --add --producer --allow-principal User:"$user" --topic "$topic" --resource-pattern-type PREFIXED --command-config "$producer_properties"
			#	
			#	log_mgmt "$ticket_num"
			#	
			#	log_zipper
			#fi
			
		else
			local missing_vars=()
			[ -z "$user" ] && missing_vars=+"$user"
			[ -z "$topic" ] && missing_vars=+"$topic"
			
			check_error "$kafka_acls_path --add prefixed producer" "${missing_vars[@]}"
		fi
		
	fi
}
				  
function add_modify_rights_complex_csv() {
	
	case $operation in
	
	1)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation read --allow-principal User:$user --topic $topic_read"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation read --allow-principal User:$user --topic $topic"
		;;
		esac
		;;
		
	2)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation describe --allow-principal User:$user --topic $topic_describe"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation describe --allow-principal User:$user --topic $topic"
		;;
		esac
		;;
		
	3)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation write --allow-principal User:$user --topic $topic_write"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --operation write --allow-principal User:$user --topic $topic"
		;;
		esac
		;;
	4)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_read --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
		;;
		esac
		;;
	5)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_write --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
		;;
		esac
		;;
	6)
		case $answer in
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_describe --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
		;;
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
		;;
		esac
		;;
		
	esac
}

#declare actual_cmd=""

function add_modify_rights() {
	
	#sh_files+=("$sh_file")
	
	if [[ "$choose_param" == "2" ]]; then
		if [[ "$operation" != "describe_configs" ]]; then
			
			topics+="$topic"
			for topic in "${topics[@]}";
			#for topic in "${array[@]}"
			do
				modify_topic_rights_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation $operation --allow-principal User:$user --topic $topic"
				echo "$modify_topic_rights_cmd" >> "$sh_file"
			done
			cat "$sh_file"
			
		elif [[ "$operation" == "describe_configs" ]]; then 
			describe_configs_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --allow-principal User:$user --operation DescribeConfigs --topic $topic"
			echo "$describe_configs_cmd" >> "$sh_file"
			cat "$sh_file"
		
		
		else
			modify_topic_rights_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation $operation --allow-principal User:$user --topic $topic"
			echo "$modify_topic_rights_cmd" >> "$sh_file"
			cat "$sh_file"
			
		fi
	
	elif [[ "$choose_param" == "1" ]]; then
		modify_consumer_gr_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --allow-principal User:$user --group $consumer_group --operation $operation"
		echo "$modify_consumer_gr_cmd" >> "$sh_file"
		cat "$sh_file"
	
	elif [[ "$choose_param" == "3" ]]; then
		if [[ "$operation" == "idempotent_write" ]]; then
			modify_idempotent_write_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --allow-principal User:$user --operation IdempotentWrite --cluster"
			echo "$modify_idempotent_write_cmd" >> "$sh_file"
			cat "$sh_file"
		fi
		
	else
		printf '%s\n' \
		"${RED}HIBA: helytelen paramétert adtál meg! Lehetőségek: group, topic vagy cluster.${NC}" \
		"${YEL}Kérlek, újból add meg a szükséges adatokat.${NC}"
						
	fi
	
	#else
	#	local missing_vars=()
	#	[ -z "$operation" ] && missing_vars=+"$operation"
	#	[ -z "$user" ] && missing_vars=+"$user"
	#	[ -z "$topic" ] && missing_vars=+"$topic"
	#
	#	check_error "$kafka_acls_path --add modify rights" "${missing_vars[@]}"
	#fi
}

function add_modify_rights_no_csv_with_transactionalid() {
	
	#sh_files+=(""$sh_file"")
	
	if { [ "$operation" == "write" ] || [ "$operation" == "read" ] || [ "$operation" == "describe" ] }; then
		modify_rights_transactional_id="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper:$zk_port --add --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation $operation"
		echo "$modify_rights_transactional_id"	
	else
		local missing_vars=()
		[ -z "$operation" ] && missing_vars=+"$operation"
		[ -z "$user" ] && missing_vars=+"$user"
		[ -z "$topic" ] && missing_vars=+"$topic"
		[ -z "$transactional_id" ] && missing_vars=+"$transactional_id"
	
		check_error "$kafka_acls_path --add modify rights with transactional-id" "${missing_vars[@]}"
	fi
}
function modify_retention_no_csv() {
	#"$kafka_configs_path" --alter --bootstrap-server "$selected_zookeeper":"$port" --entity-type topics --entity-name "$topic" --add-config retention.ms="$day_to_ms_retention"
	
	#"$kafka_topics_path --zookeeper $selected_zookeeper:$zk_port --alter --topic $topic --config retention.ms=$day_to_ms_retention"
	#"$kafka_topics_path" --bootstrap-server "$selected_broker" --alter --topic "$topic" --config retention.ms="$day_to_ms_retention" --command-config "$consumer_properties"
	echo "$kafka_configs_path --bootstrap-server $selected_broker --entity-type topics --entity-name $topic --alter --add-config retention.ms=$day_to_ms_retention --command-config $consumer_properties"
}

function modify_topic_partitions() {
	
	#"$kafka_topics_path" --alter --zookeeper "$selected_zookeeper":"$zk_port" --topic "$topic" --partitions "$partitions"
	#"$kafka_topics_path" --alter --bootstrap-server "$selected_broker":"$bts_port" --topic "$topic" --partitions "$partitions"
	echo "$kafka_topics_path --bootstrap-server $selected_broker --alter --topic $topic --partitions $partitions --command-config $consumer_properties"
	
}

function reset_offsets() {
	if [[ "$offset_reset_type" == "to-earliest" ]]; then
		"$kafka_consumer_gr_path" --bootstrap-server "$selected_broker" --command-config "$consumer_properties" --group "$consumer_group" --topic "$topic" --reset-offsets --to-earliest --execute
	
	elif [[ "$offset_reset_type" == "to-latest" ]]; then
		"$kafka_consumer_gr_path" --bootstrap-server "$selected_broker" --command-config "$consumer_properties" --group "$consumer_group" --topic "$topic" --reset-offsets --to-latest --execute
		
	else
		offset_date_format
		
		"$kafka_consumer_gr_path" --bootstrap-server "$selected_broker" --command-config "$consumer_properties" --group "$consumer_group" --topic "$topic" --reset-offsets --to-datetime "$formatted_date" --execute
		
	fi
		
	#else
	#	local missing_vars=()
	#	[ -z "$topic" ] && missing_vars=+"$topic"
	#	[ -z "$consumer_group" ] && missing_vars=+"$consumer_group"
	#	
	#	check_error "$kafka_consumer_gr_path --reset-offsets" "${missing_vars[@]}"
	#	
	#fi

}

function delete_offsets {
	if [[ "$env" == "dv" ]]; then
		"$kafka_consumer_gr_path" --bootstrap-server "$selected_broker" --command-config "$consumer2_properties" --delete-offsets --group "$consumer_group" --topic "$topic"
		
	else
		"$kafka_consumer_gr_path" --bootstrap-server "$selected_broker" --command-config "$consumer_properties" --delete-offsets --group "$consumer_group" --topic "$topic"
		
	fi
	#else
	#	local missing_vars=()
	#	[ -z "$topic" ] && missing_vars=+"$topic"
	#	[ -z "$consumer_group" ] && missing_vars=+"$consumer_group"
	#	
	#	check_error "$kafka_consumer_gr_path --delete-offsets" "${missing_vars[@]}"
	#	
	#fi
			
}

function delete_topic_complex_csv() {
	"$kafka_topics_path" --delete --topic "$topic" --bootstrap-server "$selected_broker"
}

function delete_rights_complex_csv() {

case $operation in

	1)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation read --topic $topic"
		;;
		1)
		"$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation read --topic $topic_read"
		;;
		esac
		;;
	2)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation describe --topic $topic"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation describe --topic $topic_describe"
		;;
		esac
		;;
	3)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation write --topic $topic"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --operation write --topic $topic_write"
		;;
		esac
		;;
	4)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic_read --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
		;;
		esac
		;;
	5)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic_describe --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
		;;
		esac
		;;
	6)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --topic $topic_write --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
		;;
		esac
		;;
	7)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --consumer --topic $topic"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --consumer --topic $topic_read"
		;;
		esac
		;;
	8)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --producer --topic $topic"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --producer --topic $topic_write"
		;;
		esac
		;;
	9)
		case $answer in
		2)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --producer --topic $topic- --resource-pattern-type prefixed"
		;;
		1)
		echo "$kafka_acls_path --bootstrap-server $selected_broker --remove --allow-principal User:$user --producer --topic $topic_write- --resource-pattern-type prefixed"
		;;
		esac
		;;
	esac
		
	#"$kafka_acls_path" --bootstrap-server "$selected_broker" --remove --allow-principal User:"$user" --producer --topic "$topic"
	#
	#"$kafka_acls_path" --bootstrap-server "$selected_broker" --remove --allow-principal User:"$user" --consumer --topic "$topic"
	#
	##bin/kafka-acls.sh --bootstrap-server localhost:9092 --remove --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic 
	#
	#"$kafka_acls_path" --bootstrap-server "$selected_broker" --remove --allow-principal User:"$user" --producer --topic "$topic-" --resource-pattern-type prefixed
	
	
	
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation read --allow-principal User:$user --topic $topic_read"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation read --allow-principal User:$user --topic $topic_read"
	#;;
	#
	#
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation describe --allow-principal User:$user --topic $topic_describe"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation describe --allow-principal User:$user --topic $topic_describe"
	#;;
	#
	#
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation write --allow-principal User:$user --topic $topic_write"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties zookeeper.connect=$selected_zookeeper --add --operation write --allow-principal User:$user --topic $topic_write"
	#;;
	#
	#
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_read --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_read --transactional-id $transactional_id --resource-pattern-type prefixed --operation read"
	#;;
	#
	#
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_write --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_write --transactional-id $transactional_id --resource-pattern-type prefixed --operation write"
	#;;
	#
	#
	##add_modify_rights_cmd="$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_describe --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
	##echo "$add_modify_rights_cmd" #>> "$sh_file"
	#echo "$kafka_acls_path --authorizer-properties --bootstrap-server $selected_broker --add --allow-principal User:$user --topic $topic_describe --transactional-id $transactional_id --resource-pattern-type prefixed --operation describe"
	#;;
	
	
}